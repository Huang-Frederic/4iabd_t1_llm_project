{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e633545",
   "metadata": {},
   "source": [
    "# Projet LLM - IA conversationnelle spécialisée dans les films\n",
    "## De la récupération de texte à la création d’un modèle génératif (Python)\n",
    "\n",
    "### 2.1\n",
    "\n",
    "Films (recommandations/conseils, listing etc.)\n",
    "\n",
    "Une IA conversationnel spécialisé dans les films, capable de :\n",
    "– répondre à des questions sur les acteurs et films (métadonnées IMDb),\n",
    "– suggérer des films selon les envies de l’utilisateur (genre, ambiance, popularité),\n",
    "– générer des synopsis courts ou des pitchs de films,\n",
    "– fournir la note IMDb et le nombre de votes.\n",
    "\n",
    "### 2.2\n",
    "\n",
    "Le système s’appuie sur les datasets IMDb non-commerciaux et sur un modèle distilgpt2 fine-tuné sur un corpus textuel cinéma construit à partir de ces mêmes données, afin de générer des réponses naturelles et contextualisées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d9dad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.1 Récupération des données IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58162c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titres: 12108232 lignes\n",
      "Ratings: 1607015 lignes\n",
      "Principals: 96248652 lignes\n",
      "Noms: 14912263 lignes\n",
      "Akas: 54070383 lignes\n",
      "\n",
      "=== TITLES ===\n",
      "      tconst titleType            primaryTitle           originalTitle  \\\n",
      "0  tt0000001     short              Carmencita              Carmencita   \n",
      "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
      "2  tt0000003     short            Poor Pierrot          Pauvre Pierrot   \n",
      "3  tt0000004     short             Un bon bock             Un bon bock   \n",
      "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
      "\n",
      "  isAdult startYear endYear runtimeMinutes                    genres  \n",
      "0       0      1894     NaN              1         Documentary,Short  \n",
      "1       0      1892     NaN              5           Animation,Short  \n",
      "2       0      1892     NaN              5  Animation,Comedy,Romance  \n",
      "3       0      1892     NaN             12           Animation,Short  \n",
      "4       0      1893     NaN              1                     Short  \n",
      "Colonnes: ['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes', 'genres']\n",
      "\n",
      "=== RATINGS ===\n",
      "      tconst averageRating numVotes\n",
      "0  tt0000001           5.7     2187\n",
      "1  tt0000002           5.5      306\n",
      "2  tt0000003           6.4     2272\n",
      "3  tt0000004           5.2      196\n",
      "4  tt0000005           6.2     3012\n",
      "\n",
      "=== PRINCIPALS ===\n",
      "      tconst ordering     nconst         category                      job  \\\n",
      "0  tt0000001        1  nm1588970             self                      NaN   \n",
      "1  tt0000001        2  nm0005690         director                      NaN   \n",
      "2  tt0000001        3  nm0005690         producer                 producer   \n",
      "3  tt0000001        4  nm0374658  cinematographer  director of photography   \n",
      "4  tt0000002        1  nm0721526         director                      NaN   \n",
      "\n",
      "  characters  \n",
      "0   [\"Self\"]  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "\n",
      "=== NAMES ===\n",
      "      nconst      primaryName birthYear deathYear  \\\n",
      "0  nm0000001     Fred Astaire      1899      1987   \n",
      "1  nm0000002    Lauren Bacall      1924      2014   \n",
      "2  nm0000003  Brigitte Bardot      1934       NaN   \n",
      "3  nm0000004     John Belushi      1949      1982   \n",
      "4  nm0000005   Ingmar Bergman      1918      2007   \n",
      "\n",
      "                   primaryProfession                           knownForTitles  \n",
      "0       actor,miscellaneous,producer  tt0072308,tt0050419,tt0027125,tt0025164  \n",
      "1   actress,miscellaneous,soundtrack  tt0037382,tt0075213,tt0038355,tt0117057  \n",
      "2  actress,music_department,producer  tt0057345,tt0049189,tt0056404,tt0054452  \n",
      "3      actor,writer,music_department  tt0072562,tt0077975,tt0080455,tt0078723  \n",
      "4              writer,director,actor  tt0050986,tt0069467,tt0050976,tt0083922  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"./datas\" \n",
    "\n",
    "def load_imdb_tsv(filename):\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    return pd.read_csv(filepath, sep='\\t', dtype=str, na_values='\\\\N')\n",
    "\n",
    "titles = load_imdb_tsv('title.basics.tsv.gz')\n",
    "ratings = load_imdb_tsv('title.ratings.tsv.gz')\n",
    "principals = load_imdb_tsv('title.principals.tsv.gz')\n",
    "names = load_imdb_tsv('name.basics.tsv.gz')\n",
    "akas = load_imdb_tsv('title.akas.tsv.gz')  \n",
    "\n",
    "print(f\"Titres: {len(titles)} lignes\")\n",
    "print(f\"Ratings: {len(ratings)} lignes\")\n",
    "print(f\"Principals: {len(principals)} lignes\")\n",
    "print(f\"Noms: {len(names)} lignes\")\n",
    "print(f\"Akas: {len(akas)} lignes\")\n",
    "\n",
    "print(\"\\n=== TITLES ===\")\n",
    "print(titles.head())\n",
    "print(f\"Colonnes: {titles.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n=== RATINGS ===\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\n=== PRINCIPALS ===\")\n",
    "print(principals.head())\n",
    "\n",
    "print(\"\\n=== NAMES ===\")\n",
    "print(names.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18366a",
   "metadata": {},
   "source": [
    "### 3.2 Filtrer les films (exclure séries, documentaires, courts-métrages etc.)\n",
    "\n",
    "Les datasets que l'on a récupéré sont extrêmement riches et lourds. Pour se concentrer sur les films \"classiques\", on va filtrer les titres selon plusieurs critères :\n",
    "- Exclure les titres dont le type n'est pas \"movie\" (ex : \"tvSeries\", \"short\", \"documentary\" etc.)\n",
    "- Garder uniquement les films sortis après l'an 2000 (pour se concentrer sur des films récents)\n",
    "- Exclure les films avec une note IMDb inférieure à 5.0 (pour se concentrer sur des films appréciés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf8fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering rows to only get movies: 733058 rows\n",
      "Rows after filtering movies (1980-2024): 437300 rows\n",
      "Rows after filtering runtime > 45 min: 330537 rows\n",
      "Rows after ratings merge: 222344 rows\n",
      "Rows after filtering numVotes >= 5000: 15575 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Keep only movies\n",
    "movies = titles[titles['titleType'] == 'movie'].copy()\n",
    "print(f\"Rows after filtering rows to only get movies: {len(movies)} rows\")\n",
    "\n",
    "# Keep only movies from 1980 to 2024\n",
    "movies = movies[(movies['startYear'] >= '1980') & (movies['startYear'] <= '2024')]\n",
    "print(f\"Rows after filtering movies (1980-2024): {len(movies)} rows\")\n",
    "\n",
    "# Keep only movies with a known runtime\n",
    "movies['startYear'] = movies['startYear'].astype(int)\n",
    "movies['runtimeMinutes'] = pd.to_numeric(movies['runtimeMinutes'], errors='coerce')\n",
    "\n",
    "# Keep only movies longer than 45 minutes\n",
    "movies = movies[movies['runtimeMinutes'] > 45]\n",
    "print(f\"Rows after filtering runtime > 45 min: {len(movies)} rows\")\n",
    "\n",
    "# Merge the movies dataset with ratings \n",
    "movies = movies.merge(ratings, on='tconst', how='inner')\n",
    "print(f\"Rows after ratings merge: {len(movies)} rows\")\n",
    "\n",
    "# Keep only movies with averageRating >= 5.0\n",
    "movies = movies[movies['numVotes'].astype(int) >= 5000]\n",
    "print(f\"Rows after filtering numVotes >= 5000: {len(movies)} rows\")\n",
    "\n",
    "movies['averageRating'] = pd.to_numeric(movies['averageRating'], errors='coerce')\n",
    "movies['numVotes'] = pd.to_numeric(movies['numVotes'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c214db",
   "metadata": {},
   "source": [
    "### 3.3 Ajouter les Acteurs Principaux des Films\n",
    "\n",
    "On va ajouter à notre dataset les acteurs principaux (top 3) pour chaque film, en utilisant le dataset `title.principals.tsv.gz`. Cela permettra au modèle d'améliorer la qualité des recommandations et des réponses générées, en liant certains films de styles différents à travers les différentes acteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b26578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                      primaryTitle  startYear  \\\n",
      "0  tt0035423                    Kate & Leopold       2001   \n",
      "1  tt0069049        The Other Side of the Wind       2018   \n",
      "2  tt0076276         Who's Singin' Over There?       1980   \n",
      "3  tt0078813                         The Miser       1980   \n",
      "4  tt0078935                Cannibal Holocaust       1980   \n",
      "5  tt0079285                          Saturn 3       1980   \n",
      "6  tt0079579  Moscow Does Not Believe in Tears       1980   \n",
      "7  tt0079788                  Zombie Holocaust       1980   \n",
      "8  tt0079820      The King and the Mockingbird       1980   \n",
      "9  tt0079891                The Shaolin Temple       1982   \n",
      "\n",
      "                     genres  \\\n",
      "0    Comedy,Fantasy,Romance   \n",
      "1                     Drama   \n",
      "2    Adventure,Comedy,Drama   \n",
      "3                    Comedy   \n",
      "4          Adventure,Horror   \n",
      "5   Adventure,Horror,Sci-Fi   \n",
      "6      Comedy,Drama,Romance   \n",
      "7  Adventure,Horror,Mystery   \n",
      "8  Animation,Family,Fantasy   \n",
      "9       Action,Comedy,Drama   \n",
      "\n",
      "                                              actors  averageRating  numVotes  \n",
      "0  Meg Ryan, Hugh Jackman, Liev Schreiber, Brecki...            6.4     92899  \n",
      "1  John Huston, Oja Kodar, Peter Bogdanovich, Sus...            6.7      8412  \n",
      "2  Pavle Vuisic, Dragan Nikolic, Danilo 'Bata' St...            8.7     17656  \n",
      "3  Louis de Funès, Franck Cabot-David, Hervé Bell...            6.6      5596  \n",
      "4  Robert Kerman, Francesca Ciardi, Perry Pirkane...            5.8     65855  \n",
      "5  Farrah Fawcett, Kirk Douglas, Harvey Keitel, E...            5.1     11340  \n",
      "6  Vera Alentova, Aleksey Batalov, Irina Muravyov...            8.0     15402  \n",
      "7  Ian McCulloch, Alexandra Delli Colli, Sherry B...            5.2      6449  \n",
      "8  Jean Martin, Pascal Mazzotti, Raymond Bussière...            7.7      5968  \n",
      "9  Jet Li, Hai Yu, Chenghui Yu, Lan Ding, Jianqia...            6.8      5042  \n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Keep the 5 principal actors for each film\n",
    "principals['ordering'] = pd.to_numeric(principals['ordering'], errors='coerce')\n",
    "actors_in_films = principals[\n",
    "    (principals['category'].isin(['actor', 'actress'])) &\n",
    "    (principals['ordering'] <= 5)  \n",
    "].copy()\n",
    "\n",
    "actors_in_films = actors_in_films.merge(\n",
    "    names[['nconst', 'primaryName']], \n",
    "    on='nconst', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Regroup actors by film\n",
    "actors_by_film = actors_in_films.groupby('tconst')['primaryName'].apply(\n",
    "    lambda x: ', '.join(x.dropna().unique())\n",
    ").reset_index()\n",
    "actors_by_film.columns = ['tconst', 'actors']\n",
    "\n",
    "movies = movies.merge(actors_by_film, on='tconst', how='left')\n",
    "movies['actors'] = movies['actors'].fillna('Unknown')\n",
    "\n",
    "print(movies[['tconst', 'primaryTitle', 'startYear', 'genres', 'actors', 'averageRating', 'numVotes']].head(10))\n",
    "\n",
    "movies.to_parquet('movies_filtered.parquet', index=False)\n",
    "movies.to_csv('movies_filtered.csv', index=False)\n",
    "\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be43f0",
   "metadata": {},
   "source": [
    "### 4. Génération du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276b924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15575/15575 [00:00<00:00, 19420.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15575 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "movies = pd.read_parquet('movies_filtered.parquet')\n",
    "corpus_texts = []\n",
    "\n",
    "templates = [\n",
    "    # --- without scores ---\n",
    "    \"{title} est un film {genres} sorti en {year}, porté par {actors}. Il mise surtout sur l’ambiance et le récit pour immerger le spectateur.\\n\\n\",\n",
    "    \"Sorti en {year}, {title} est un long-métrage {genres} avec {actors}. Le film se distingue par son ton particulier et sa mise en scène.\\n\\n\",\n",
    "    \"{title} ({year}) est un film {genres}. Avec {actors}, il propose une histoire qui marie émotions et divertissement.\\n\\n\",\n",
    "    \"Dans {title}, sorti en {year}, {actors} incarnent des personnages marquants. Ce film {genres} s’adresse surtout à ceux qui aiment les univers travaillés.\\n\\n\",\n",
    "    \"{title} est une production {genres} de {year}. Le casting, mené par {actors}, donne une identité forte au film.\\n\\n\",\n",
    "    \"{title}, sorti en {year}, appartient au genre {genres}. Il s’appuie sur {actors} pour donner vie à son récit.\\n\\n\",\n",
    "    \"Avec {actors} au casting, {title} propose une expérience {genres} sortie en {year}, centrée sur ses personnages et son atmosphère.\\n\\n\",\n",
    "\n",
    "    # --- quality scores ---\n",
    "    \"{title} est un film {genres} sorti en {year} avec {actors}. Il est généralement {appreciation}.\\n\\n\",\n",
    "    \"Avec {actors} en tête d’affiche, {title} propose un récit {genres} sorti en {year}. Le film est considéré comme {appreciation}.\\n\\n\",\n",
    "    \"{title} ({year}) appartient au genre {genres}. Grâce à {actors}, le film a laissé une impression {appreciation} sur son public.\\n\\n\",\n",
    "    \"Parmi les films {genres} sortis en {year}, {title} se distingue par son casting ({actors}) et un accueil {appreciation}.\\n\\n\",\n",
    "    \"{title} est souvent cité comme un exemple {genres} {appreciation}, notamment grâce à la performance de {actors}.\\n\\n\",\n",
    "\n",
    "    # --- with score ---\n",
    "    \"{title} est un film {genres} sorti en {year} avec {actors}. Sur IMDb, il bénéficie d’une note d’environ {rating}/10, signe d’un intérêt réel du public.\\n\\n\",\n",
    "    \"Film {genres} de {year}, {title} réunit {actors}. Sa note autour de {rating}/10 sur IMDb reflète des retours globalement positifs.\\n\\n\",\n",
    "    \"{title} ({year}) met en avant {actors} dans un récit {genres}. La communauté IMDb lui attribue une note proche de {rating}/10.\\n\\n\",\n",
    "    \"{title} est considéré comme un film {genres} solide. Sorti en {year} avec {actors}, il est évalué à environ {rating}/10 par les utilisateurs d’IMDb.\\n\\n\",\n",
    "    \"Parmi les films {genres}, {title} ({year}) avec {actors} obtient une note avoisinant {rating}/10 sur IMDb, ce qui traduit son accueil.\\n\\n\",\n",
    "    \"{title}, film {genres} sorti en {year}, met en scène {actors}. Sa note sur IMDb tourne autour de {rating}/10, ce qui reste cohérent avec les avis du public.\\n\\n\",\n",
    "\n",
    "    # --- Recommendation ---\n",
    "    \"Si tu cherches un film {genres} sorti en {year}, {title} avec {actors} est une option intéressante à considérer.\\n\\n\",\n",
    "    \"Pour une soirée {genres}, {title} ({year}) avec {actors} peut être un bon choix, souvent {appreciation} par ceux qui l’ont vu.\\n\\n\",\n",
    "]\n",
    "\n",
    "\n",
    "def rating_to_appreciation(rating):\n",
    "    try:\n",
    "        r = float(rating)\n",
    "    except (TypeError, ValueError):\n",
    "        return \"accueilli de manière mitigée\"\n",
    "    if r >= 8.0:\n",
    "        return \"très apprécié du public\"\n",
    "    elif r >= 7.0:\n",
    "        return \"bien accueilli par les spectateurs\"\n",
    "    elif r >= 6.0:\n",
    "        return \"reçu de façon mitigée mais intéressant pour certains\"\n",
    "    else:\n",
    "        return \"plutôt mal reçu par le public\"\n",
    "\n",
    "def format_genres(genres_str):\n",
    "    if pd.isna(genres_str) or genres_str == 'Unknown':\n",
    "        return 'inconnu'\n",
    "    genres = genres_str.split(',')\n",
    "    if len(genres) == 1:\n",
    "        return f\"de {genres[0].lower()}\"\n",
    "    elif len(genres) == 2:\n",
    "        return f\"de {genres[0].lower()} et de {genres[1].lower()}\"\n",
    "    else:\n",
    "        return f\"de {', '.join(g.lower() for g in genres[:-1])} et de {genres[-1].lower()}\"\n",
    "\n",
    "\n",
    "def format_actors(actors_str, max_actors=3):\n",
    "    if pd.isna(actors_str) or actors_str == 'Unknown':\n",
    "        return \"des acteurs inconnus\"\n",
    "    actors = actors_str.split(', ')\n",
    "    if len(actors) > max_actors:\n",
    "        actors = actors[:max_actors]\n",
    "    if len(actors) == 1:\n",
    "        return actors[0]\n",
    "    elif len(actors) == 2:\n",
    "        return f\"{actors[0]} et {actors[1]}\"\n",
    "    else:\n",
    "        return f\"{', '.join(actors[:-1])} et {actors[-1]}\"\n",
    "    \n",
    "\n",
    "for idx, row in tqdm(movies.iterrows(), total=len(movies)):\n",
    "    title = row['primaryTitle']\n",
    "    year = row['startYear']\n",
    "    genres = format_genres(row['genres'])\n",
    "    actors = format_actors(row['actors'])\n",
    "    rating = row['averageRating']\n",
    "    votes = row['numVotes']\n",
    "    appreciation = rating_to_appreciation(rating)\n",
    "\n",
    "    template = random.choice(templates)\n",
    "\n",
    "    text = template.format(\n",
    "        title=title,\n",
    "        year=year,\n",
    "        genres=genres,\n",
    "        actors=actors,\n",
    "        rating=rating,\n",
    "        votes=f\"{votes:,}\",\n",
    "        appreciation=appreciation,\n",
    "    )\n",
    "    corpus_texts.append(text)\n",
    "\n",
    "\n",
    "print(f\"{len(corpus_texts)} texts\")\n",
    "\n",
    "import pickle\n",
    "with open('corpus_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_texts, f)\n",
    "\n",
    "with open('corpus_sample.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(corpus_texts[:100]))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b601f9c",
   "metadata": {},
   "source": [
    "5. Creation du dataset pour le fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a713cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size : 15575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 15575/15575 [00:00<00:00, 1639181.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "with open('corpus_texts.pkl', 'rb') as f:\n",
    "    corpus_texts = pickle.load(f)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_texts = [clean_text(t) for t in corpus_texts]\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": cleaned_texts})\n",
    "\n",
    "print(f\"dataset size : {len(dataset)}\")\n",
    "\n",
    "dataset.save_to_disk('imdb_corpus_dataset')\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c422f",
   "metadata": {},
   "source": [
    "6. Choisir un modèle de base : distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ff9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "dataset = load_from_disk('imdb_corpus_dataset')\n",
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313f60b",
   "metadata": {},
   "source": [
    "7. Tokenisation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c095a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenisation: 100%|██████████| 15575/15575 [00:01<00:00, 13590.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 15575 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "block_size = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=block_size,\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenisation\"\n",
    ")\n",
    "\n",
    "print(f\"Tokenized {len(tokenized_dataset)} items\")\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc29818",
   "metadata": {},
   "source": [
    "### 8. Prepare Fine-tuning with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc9e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='382' max='10515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  382/10515 08:42 < 3:52:21, 0.73 it/s, Epoch 0.11/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 34\u001b[0m\n\u001b[0;32m     24\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     25\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     26\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 8.2\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2672\u001b[0m )\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2680\u001b[0m ):\n\u001b[0;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   4026\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1068\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1068\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:925\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    923\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 925\u001b[0m outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m    926\u001b[0m     hidden_states,\n\u001b[0;32m    927\u001b[0m     past_key_values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    928\u001b[0m     cache_position,\n\u001b[0;32m    929\u001b[0m     causal_mask,\n\u001b[0;32m    930\u001b[0m     head_mask[i],\n\u001b[0;32m    931\u001b[0m     encoder_hidden_states,  \u001b[38;5;66;03m# as a positional argument for gradient checkpointing\u001b[39;00m\n\u001b[0;32m    932\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    933\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    934\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    936\u001b[0m )\n\u001b[0;32m    938\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:449\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, past_key_values, cache_position, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    448\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 449\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m    451\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:375\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[\u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m    374\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m--> 375\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[0;32m    377\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\activations.py:62\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.044715\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = \"./distilgpt2-imdb-finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "# 8.1\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 8.2\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df11ad9",
   "metadata": {},
   "source": [
    "### 9. Sauvegarder le modèle fine-tuné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [390/390 02:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6746909618377686, 'eval_runtime': 122.1659, 'eval_samples_per_second': 12.753, 'eval_steps_per_second': 3.192, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d910945",
   "metadata": {},
   "source": [
    "### 10. Générer du texte avec le modèle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROMPT: Propose-moi un film d'action récent avec de bons effets spéciaux.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération 1 ---\n",
      "Ce film de drama et est un film de thriller sorti en 2011, il obtient une note of 6.6/10 sur IMDb. Avec des acteurs inconnus, il obtient une noteandie note 7.2/10 sur IMDb. Note IMDb: 5.8/10 (5,955 votes). Score: 3.7/10 sur IMDb. Note IMDb: 4.3/10 sur IMDb. Note IMDb: 6.0/10 sur IMDb. Note IMDb.: 5.4/10 sur IMDb. Note IMDb 20/10 sur IMDb. Note IMDb: 6.1/10 sur IMDb. Note IMDb: 5.9/10 sur IMB. Note IMDb: 5.3/10 sur IMDb. Note IMDb: 4.9 in 7.6/10 sur IMDb. Note IMDb: 5.6/10 sur IMDb. Note IMDb 8 2.1/10 sur IMDb. Note IMDb: 3.2/11 sur IMDb. Note IMDb: 4.4/12 Surim et 1.8/10 sur IMDb. Note IMDb: 3\n",
      "\n",
      "--- Génération 2 ---\n",
      "Ce film de action, comedy et est un film de crime sorti en 2023. Avec Nicolas Cage, Julianne Moore et Dermot Mulroney, il obtient une note of 6.6/10 sur IMDb.3/10 (8,711 votes). Score: 7.4/10 sur IMDb.1/10 (15,941 votes). Score: 8.0/10 sur IMDb.2/10 (5,948 votes). Score: 5.1/10 sur IMDb.1/10 (12,822 votes). Note IMDb: 4.8/10 sur IMDb.1/10 (21,644 votes). Score: 2.2/10 sur IMD.4 in 4.3/10 sur IMDb.1/10 Vantage Point. Note IMDb: 3.7/10 sur IMDb.0 Surfer: 5.3/10 sur IMDb.0 to IMDb.1 sur IMDb.0 sur IMDb.xhope, il obtient une note du 4.5/10 sur IMDb.2/10 sur IMDb.1 sur IMDb.6 sur IMDb.3 sur IMDb\n",
      "\n",
      "--- Génération 3 ---\n",
      "Ce film de action, crime et est un film de drama sorti en 2012! Score: 7.2/10.3/10.7 sur IMDb. Avec Demetrius Kondikisiusz Gubatowiakoufukrijianin et Tomasz Kostasiewiczakowski.. Note IMDb: 6.1/10 (6,941 votes). Score: 5.0/10 (8,072 votes). Score: 8.4/10 (12,871 votes). Score: 4.8/10.5/10.6/10.6/11.6. Score: 1.8/10.1/10.2/10.5. Score: 3.6/10.4/10.9.8. Score: 2.4/10.2/10.9.6/10.5. Score: 6.2/10.2/10.6/10.7. Score: 5.7/10.7/10.6/10.8 -9.4/10.2 rating. Score: 9.0/10.6/10.3/10.8 -17,770 votes. Score\n",
      "\n",
      "============================================================\n",
      "PROMPT: Je veux un film avec Tom Cruise. Que me conseilles-tu ?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération 1 ---\n",
      "une note de 7.2/10 sur IMDb. Avec Will Forte, John Leguizamo et Jean Reno Jr.. Note IMDb: 6.9/10 (7,893 votes). IMDb: 4.6/10 (5,078 votes). Score: 5.1/10 (11,879 votes). IMDb: 2.9/10 (15,564 votes). IMDb: 3.0/10 (28,819 votes). IMDb est un film de biography, drama et en music sorti en 2017. IMDb: 8.4/10 (34,945 votes) il obtient une note des acteurs inconnus. IMDb: 1.8/10 (17,921 votes). Score of 6.7/10 sur IMDb: 7.5/10 sur IMDb: 5.9/10 sur IMDb: 4.9/10 sur IMDb.: 4.5/12 sur IMDb: 5.5/10 sur IMDb: 3.2/10 sur IMDb: 2.2 the Movie. IMDb: 6.6/10 sur IMDb: 6.7/10 sur IMDb E\n",
      "\n",
      "--- Génération 2 ---\n",
      "une note de 7.8 sur IMDb. Sunil Gulati, Ileana Rosso et Nayanthara Sen. Ce film de action, crime et est un film de drama sorti en 6.1 sur IMDb.7/10 sur 4.4/10 sur IMDb.5/10 sur 5.5/10 sur IMDb.9/10 sur 6.0 sur IMDb.3/10 sur 3.6/10 sur IMDb.2/10 sur 2.2/10 sur IMDb.3/10 sur 1.7/10 sur IMDb.7: 4.6/10 sur IMDb.2/10 sur 2.3/10 sur 1.3/10 sur IMDb.5 (12,981 votes). Score: 8.0/10 sur IMDb.6/10 sur 4.6/10 sur 1.4/11 IMDb.6 -5.4/10 sur 1.9/10 sur IMDb.7s 3.7/10 sur 1.9/10 sur IMDb.5 sur 1.8m IMDb.8 sur 3.9andhra Pradesh. Score: 7.1/10 sur IMDb.3\n",
      "\n",
      "--- Génération 3 ---\n",
      "il obtient une note de 7.3/10 sur IMDb. Avec des acteurs inconnus, il obtient une 6.4/10 sur IMDb. Ce film de documentary et est un film de 8.1/10 sur IMDb. Je sci-fi sorti en 2022 (2022,078 votes). Score: 5.5/10 sur IMDb. Ce film de 4.6/10 sur IMDb. Ce drama et music sorti en 2024. Score: 2.9/10 sur IMDb. Note IMDb: 1.8/10 sur IMDb. Note IMDb.: 3.2/10 sur IMDb. Note IMDb!: 6.7/10 sur IMDb. Note IMDb! IMDb: 6.6/10 sur IMDb. Note IMDb!: 6.6a sur IMDb. Note IMDb!! IMDb!: 5.7/11 sur IMDb. Note IMDb! IMDb!: 4.2/10 sur IMDb. Note IMDb!: 6.9a sur IMDb. Note IMDb!: 5.3d IMDb! IMDb! IMDb! IMDb! IMDb! IMDb!: 4.\n",
      "\n",
      "============================================================\n",
      "PROMPT: Donne-moi un court synopsis d'un film de science-fiction sorti dans les années 2000.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération 1 ---\n",
      "Avec James McAvoy, Richard Dreyfuss et Ben Affleck, il obtient une note en 5.4/10 sur IMDb.3/10 sur IMDb.1/10 (36,846 votes). Score: 6.5/10 sur IMDb.7/10.5/10 sur IMDb.6/10 sur IMDb.9/10 sur IMDb.2/10 sur IMDb.3/10 sur IMDb.0/10 sur 4.7/10 sur IMDb.8/10 sur IMDb.1 Sur IMDb.1/10 sur IMDb.7 a été réalisé avec Albert Brooks III Jr., Michael Caine II IVsonscoffernan Taylor Carter Izzardine Sosao Tsurinozaiszioviciuscuirio Vidaliniuciyaniuya Venandati Uptinu. Ce film de drama et music a une note of 7.8 sur IMDb.4/10 sur IMDb.2 est inconnus. Note IMDb.2 sur IMDb.7/10 sur IMDb.0a sur ImDb.5 sur IMDb.1 sur IMDb\n",
      "\n",
      "--- Génération 2 ---\n",
      "Avec Robert Duvall, Richard Schiff et Daniel Tuch, il obtient une note des acteurs inconnus. Ce film de 6.9/10 sur IMDb.2/10 sur IMDb.8/10 sur IMDb.1/10 (5,065 votes). Score: 5.4/10 sur IMDb.3/10 sur IMDb.6/10 sur IMDb.7/10 sur IMDb.7 in 7.6/10 sur IMDb.6/10 sur IMDb.8/10 sur IMDb.8/10 sur ImDb.7 est un film de biography, drama et family sorti en 2003. Avec Nicholas Hoult, Paul Rudd et Ed Harris, il obtient une note de 4.4/10 sur IMDb.5 on IMDb.6/10 sur IMDb.3/11 sur IMDb.8 8/10 sur IMDb.3s sur IMDb.8/10 sur IMDb.2 sur IMDb.7a il obtient une note of 6.6/10 sur IMDb.1 sur IMDb.1 sur IMDb.6 sur IMDb.6 sur IMDb.3 sur\n",
      "\n",
      "--- Génération 3 ---\n",
      "Avec Robert De Niro, Paul Giamatti et John Goodman, il obtient une note des acteurs inconnus, il obtient une 6.2/10 sur IMDb.3/10 sur IMDb.7/10 (6,065 votes). Score: 7.4/10 sur IMDb.8/10 sur IMDb.5/10 sur IMDb.9/10 sur IMDb.1/10 sur IMDb.3/10 sur IMDb.3/10 sur IMDb.5 est un film de documentary a une note of 8.0 sur IMDb.3/10 sur IMDb.7 5.6/10 sur IMDb.7 1.9/10 sur IMDb.6 sur IMDb.1 sur IMDb.7/10 sur MTS, il obtient une note 4.1/10 sur IMDb.6 sur IMDb.5 en 2010. Note IMDb: 6.4/10 sur IMDb.7/10 sur IMDb.5 sur IMAX, Viacom and 3M TV sur IMDb.2/10 sur IMDb.5 sur IMDb.6 Sur IMDb.4 Lola, Inc\n",
      "\n",
      "============================================================\n",
      "PROMPT: Quelle est la note du film Inception et pourquoi est-il si populaire ?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération 1 ---\n",
      "Avec Nicolas Cage, Jai Courtney Scott Thomas Jr. et Elizabeth Banks.. Note IMDb: 6.5/10 (48,945 votes). IMDb: 5.7/10 (23,859 votes). Score: 7.1/10 (21,552 votes). IMDb de action, adventure et une note de thriller a il obtient une note of 5.3/10 sur IMDb. Score: 4.6/10 (26,084 votes). Score: 3.3/10 (16,844 votes). IMDb: 5.0/10 (14,879 votes) -2.5/10 sur IMDb: 5.2/10 sur IMDb.: 4.7/10 sur IMDb: 5.7/10 sur IMDb: 4.3/10 sur IMDb: 5.5/10 sur IMDband Quelle: 4.8/10 sur ImDband 6.3x IMDb(8,963 votes). IMDb: 5.0/10 sur IMDbendiève des acteurs inconnus. IMDb: 5.6/10 sur IMDbst il obtient une note en 8.\n",
      "\n",
      "--- Génération 2 ---\n",
      "Avec Philippe Nivet, Mélanie Laurent et Jean Le Bourgne. Ce film de drama et une thriller sorti en 2020 il obtient une note of 7.1/10 sur IMDb.7/10 sur IMDb.6/10 sur IMDb.8/10 sur 6.5/10 sur IMDb.3/10 sur 6.6/10 sur IMDb.4 in 8.0/10 sur IMDb.2/10 sur 5.9/10 sur IMDb.3/10 sur 5.9/10 sur 4.1/10 sur 5.2/10 sur 3.4/10 sur 2.2/10 sur 1.9/10 sur 1.6/10 sur 1.9/10 sur 1.9 (23,779 votes). Score: 9.5/10 sur IMDb.1/10 sur 5.9/10 sur 1.9/20 sur IMDb.6and IMDb.. 7.6/10 sur 5.6/10 sur 3.0/10 sur 4.8 on IMDb... Score: 11.4/10 sur 5.7/10 sur 4.2/10 sur 3.9/10 sur\n",
      "\n",
      "--- Génération 3 ---\n",
      "Avec Joseph Fiennes, Michelle Monaghan et David Arquette. Ce film de crime, drama et sur musical sorti en 2022! il obtient une note of 6.3/10 sur IMDb.7/10 sur IMDb.4/10 (8,037 votes). Note IMDb: 5.9/10 (6,564 votes). Score: 7.1/10 sur IMDb.2/10 (11,564 votes). Score: 4.7/10 sur IMDb.5/10 (13,724 votes). Score: 8.0/10 (12,725 votes). Score.: 2.8/10 (17,724 votes) IMDb: 3.6/10 sur IMDb.0andation: 1.8/10 sur IMDb.1 sur IMDb.1 sur IMDb.2 sur IMDb.2 sur IMDb.3 un film de mystery et des acteurs inconnus. Note IMDb: 5.9/10 sur IMDb.1 sur IMDb.2 sur IMDb.3 sur IMDb.4 sur IMDb.5 sur IMDb.4 Sursonic 7.8/10 sur IMDb\n",
      "\n",
      "============================================================\n",
      "PROMPT: J'ai envie d'un film drôle et intelligent. Une idée ?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération 1 ---\n",
      "une note de 7.9 sur IMDb. Avec Jang Dong-ho, Park Yoon-jae et Yeong Seo-joo. Score: 6.5/10.7/10. Note IMDb: 8.1/10 (8,904 votes). Score of 4.5/10 sur IMDb. Note Tang Hwan Kim et Jung Hyuk-soo. IMDb: 5.6/10 (12,828 votes). IMDb: 3.3/10 (19,848 votes). Note est un film de comedy, drama et en romance sorti en 2022. Score: 2.0/10 sur IMDb. Note IMDb.: 1.9/10 sur IMDb. Note IMDb: 7.2/10 sur IMDb. Note IMDb: 7.4/11 sur IMDb. Note IMDb: 6.4/10 sur IMDb. Note IMDb avec Kang Hee-ju, Kim Soo-jung et Kim Byung-won. IMDb: 6.4/10 sur IMDb. Note IMB: 6.9/10 sur IMDb. Note IMDb: 6.8/10 sur IMDb.\n",
      "\n",
      "--- Génération 2 ---\n",
      "une note de 6.7/10 sur IMDb. Thiruvothu, Anjali D'Cruz et Pankaj Tripathi Vijayakonda. Ce film de drama et est un film de musical sorti en 2013, il obtient une note de 7.4/10 sur IMDb. Avec Shraddha Roshanupadhyay Jr., il obtient une note of 8.2/10 sur IMDb. Note IMDb: 5.7/10 sur IMDb. Note IMDb: 4.8/10 sur IMDb. Note IMDb: 1.9/10 sur IMDb. Note IMDb: 3.0/10 sur IMDb. Note IMDb: 2.3/10 sur IMDb. Note IMDb.: 1.6/10 sur IMDb. Note IMDb: 1.8/10 sur IMDb. Note IMDb (13,476 votes). IMDb: 9.1/11 sur IMDb. Note IMDb: 6.5/10 sur IMDb. See IMDb: 5.3/10 sur IMDb. Note IMDb: 6.6 in 4.5/10 sur IMDb. IMDb: 5\n",
      "\n",
      "--- Génération 3 ---\n",
      "une note de 7.1 sur IMDb. Avec Ajay Devgn, Kriti Sanonan Jr.. Ce film de crime, drama et est un film de history sorti en 2004! il obtient une note of 6.9/10 sur IMDb. Avec Akshay Kumar, Anushka Sharma Thakur Jhunjian et Ajay Sethupathi Rajkumar Prasadhaniamji Jonas, il obtient une note des acteurs inconnus. Note IMDb: 8.3/10 sur IMDb. Avec Sushant Singh Kaani Khanna, Dhanushik Roshan et Manoj Kapoor Khan Bhavan Tiffin III., il obtient une noteand du 5.2/10 sur IMDb. Avec Shraddha Dhawan Jaishwadi Rao Mandhi et Nani Mukerjee, il obtient une noteand 4.8/10 sur IMDb. il obtient une noteand 3.9/10 sur IMDb. il obtient une noteand 2.4/5 sur IMDb. il obtient une noteand 1.8/10 sur IMDb. il obt\n",
      "\n",
      "============================================================\n",
      "PROMPT: Liste les acteurs principaux du film Titanic.\n",
      "============================================================\n",
      "\n",
      "--- Génération 1 ---\n",
      "Ce film de documentary et est un film sorti en 2023, il obtient une note des 7.3/10 sur IMDb. Avec des acteurs inconnus, il obtient une 6.6/10 sur IMDb. Anissa Bledelogui, Antonio Rochaazquez Jr., and Anthony Anderson-Staunton Cossicko: 4.9/10 sur IMDb. Score: 8.2/10 sur IMDb. Note IMDb: 1.9/10 sur IMDb. Score: 5.8/10 sur IMDb. Note IMDb.: 3.1/10 sur IMDb. Note IMDb: 7.7/10 sur IMDb. Note IMDb!: 2.0/10 sur IMDb. Note IMDb (11,743 votes). IMDb: 7.5/10 sur IMDb. Note IMDb: 5.4/10 sur IMDb. Note IMDb: 5.2/20 sur IMandation: 6.1/10 sur IMDb. Note IMDb: 6.4/10 sur Imandation of Interest: 7.5 Surimed: 7.7/10 sur IMDb. Note\n",
      "\n",
      "--- Génération 2 ---\n",
      "Ce film de drama et est un film de thriller sorti en 2017, il obtient une note IMDb: 5.6/10 (7,907 votes). Avec des acteurs inconnus, il obtient une note of 7.3/10 sur IMDb. Score: 6.1/10 sur IMDb. Note IMDb.: 4.8/10 (5,038 votes). Score: 8.2/10 sur IMDb. Note 3.4/10 sur IMDb. Note 2.8/10 sur IMDb. Note 1.8/10 sur IMDb. Note 0.5/10 sur IMDb. Note 0andation: 5.9/10 sur IMDb. Note 1.9 in IMDb. Note 1.5 SurimDb. Note 11.5 sur IMD. Note 3.9/11 sur IMDb. Note 1.8-10 sur IMDb. Note 9.3/10 sur IMDb. Note 1.9-10 sur IMDb. Note 10.5 sur IMDb. Note D.2 sur IMDb. Note N/A sur IMDb. Note 1.8 sur IMDb. Note S/H/S\n",
      "\n",
      "--- Génération 3 ---\n",
      "Ce film de documentary et history sorti en 2024, il obtient une note of 7.2/10 sur IMDb. Avec des acteurs inconnus, il obtient une 6.4/10 sur IMDb. Avec des 5.4/10 sur IMDb. Avec des 8071,742 votes. Score: 3.9/10 sur IMDb. Avec des acteurs inconnt une note est un film de 2023,869 votes. Note IMDb: 7.3/10 sur IMDb. Avec des actei avec des acteurs inconnus, il obtient une noteand scène des 4.2/10 sur IMDb. Ce film de 1988, The Big Short met en 9.6/10 sur IMDb. Aveci il obtient une notere 2.5/10 sur IMDb. Avecéant une notea une noteé 7.0/10 sur IMDb. Avec des actezons il obtient une 7.5/10 sur IMDb. Avec des acteur inconnaisseur Philippe Ruedaierl, Emmanuelle Bonnaire et Bruno Paremb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Liste les acteurs principaux du film Titanic. Ce film de documentary et est un film sorti en 2023, il obtient une note des 7.3/10 sur IMDb. Avec des acteurs inconnus, il obtient une 6.6/10 sur IMDb. Anissa Bledelogui, Antonio Rochaazquez Jr., and Anthony Anderson-Staunton Cossicko: 4.9/10 sur IMDb. Score: 8.2/10 sur IMDb. Note IMDb: 1.9/10 sur IMDb. Score: 5.8/10 sur IMDb. Note IMDb.: 3.1/10 sur IMDb. Note IMDb: 7.7/10 sur IMDb. Note IMDb!: 2.0/10 sur IMDb. Note IMDb (11,743 votes). IMDb: 7.5/10 sur IMDb. Note IMDb: 5.4/10 sur IMDb. Note IMDb: 5.2/20 sur IMandation: 6.1/10 sur IMDb. Note IMDb: 6.4/10 sur Imandation of Interest: 7.5 Surimed: 7.7/10 sur IMDb. Note'},\n",
       " {'generated_text': 'Liste les acteurs principaux du film Titanic. Ce film de drama et est un film de thriller sorti en 2017, il obtient une note IMDb: 5.6/10 (7,907 votes). Avec des acteurs inconnus, il obtient une note of 7.3/10 sur IMDb. Score: 6.1/10 sur IMDb. Note IMDb.: 4.8/10 (5,038 votes). Score: 8.2/10 sur IMDb. Note 3.4/10 sur IMDb. Note 2.8/10 sur IMDb. Note 1.8/10 sur IMDb. Note 0.5/10 sur IMDb. Note 0andation: 5.9/10 sur IMDb. Note 1.9 in IMDb. Note 1.5 SurimDb. Note 11.5 sur IMD. Note 3.9/11 sur IMDb. Note 1.8-10 sur IMDb. Note 9.3/10 sur IMDb. Note 1.9-10 sur IMDb. Note 10.5 sur IMDb. Note D.2 sur IMDb. Note N/A sur IMDb. Note 1.8 sur IMDb. Note S/H/S'},\n",
       " {'generated_text': 'Liste les acteurs principaux du film Titanic. Ce film de documentary et history sorti en 2024, il obtient une note of 7.2/10 sur IMDb. Avec des acteurs inconnus, il obtient une 6.4/10 sur IMDb. Avec des 5.4/10 sur IMDb. Avec des 8071,742 votes. Score: 3.9/10 sur IMDb. Avec des acteurs inconnt une note est un film de 2023,869 votes. Note IMDb: 7.3/10 sur IMDb. Avec des actei avec des acteurs inconnus, il obtient une noteand scène des 4.2/10 sur IMDb. Ce film de 1988, The Big Short met en 9.6/10 sur IMDb. Aveci il obtient une notere 2.5/10 sur IMDb. Avecéant une notea une noteé 7.0/10 sur IMDb. Avec des actezons il obtient une 7.5/10 sur IMDb. Avec des acteur inconnaisseur Philippe Ruedaierl, Emmanuelle Bonnaire et Bruno Paremb'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "model_path = \"./distilgpt2-imdb-finetuned\"\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0 if torch.cuda.is_available() else -1  \n",
    ")\n",
    "\n",
    "def generate_response(prompt, max_length=150, num_sequences=3):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_sequences,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    for i, out in enumerate(outputs, 1):\n",
    "        generated_text = out[\"generated_text\"][len(prompt):].strip()\n",
    "        print(f\"\\n--- Génération {i} ---\")\n",
    "        print(generated_text)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "generate_response(\n",
    "    \"Propose-moi un film d'action récent avec de bons effets spéciaux.\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Je veux un film avec Tom Cruise. Que me conseilles-tu ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Donne-moi un court synopsis d'un film de science-fiction sorti dans les années 2000.\",\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Quelle est la note du film Inception et pourquoi est-il si populaire ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"J'ai envie d'un film drôle et intelligent. Une idée ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Liste les acteurs principaux du film Titanic.\",\n",
    "    max_length=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df92157",
   "metadata": {},
   "source": [
    "### 11. Evaluation simple du modèle génératif\n",
    "\n",
    "- [ ] Cohérence : le texte est-il logique, grammatical ?\n",
    "->\n",
    "\n",
    "- [ ] Style : ressemble-t-il aux textes d’entraînement ?\n",
    "->\n",
    "\n",
    "- [ ] Spécialisation : le modèle reste-t-il dans le bon domaine (cuisine, IT, etc.) ?\n",
    "->\n",
    "\n",
    "- [ ] Hallucinations : invente-t-il des choses fausses / dangereuses ?\n",
    "->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02563ec6",
   "metadata": {},
   "source": [
    "### 12. Extensions possibles\n",
    "\n",
    "#### 12.1 Alpaca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8cd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset d’instructions créé: 5000 exemples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5000 examples [00:00, 331817.35 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5000/5000 [00:00<00:00, 1619422.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Quels sont les acteurs principaux du film The Last Days of Disco ?\n",
      "Réponse: Les principaux acteurs de The Last Days of Disco (1998) sont Chloë Sevigny, Kate Beckinsale, Chris Eigeman, Mackenzie Astin, Matt Keeslar.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "movies = pd.read_parquet(\"movies_filtered.parquet\")\n",
    "\n",
    "instructions = []\n",
    "\n",
    "def pick_random_movie(df):\n",
    "    return df.sample(1).iloc[0]\n",
    "\n",
    "for _ in range(5000):\n",
    "    row = pick_random_movie(movies)\n",
    "    title = row[\"primaryTitle\"]\n",
    "    year = row[\"startYear\"]\n",
    "    genres = row[\"genres\"]\n",
    "    actors = row[\"actors\"]\n",
    "    rating = row[\"averageRating\"]\n",
    "    votes = row[\"numVotes\"]\n",
    "    appreciation = rating_to_appreciation(rating)\n",
    "\n",
    "    itype = random.choice([\"reco\", \"resume\", \"actors\", \"popularity\", \"vibe\"])\n",
    "\n",
    "    if itype == \"reco\":\n",
    "        instruction = random.choice([\n",
    "            f\"Recommande-moi un bon film {genres.lower()} à regarder ce soir.\",\n",
    "            f\"Je cherche un film {genres.lower()} récent à voir. Tu me proposes quoi ?\",\n",
    "            f\"Si j’aime les films {genres.lower()}, quel film me conseilles-tu ?\",\n",
    "        ])\n",
    "        output = (\n",
    "            f\"Tu peux regarder {title} ({year}). \"\n",
    "            f\"C’est un film {genres.lower()} avec {actors}. \"\n",
    "            f\"Il est {appreciation}.\"\n",
    "        )\n",
    "\n",
    "    elif itype == \"resume\":\n",
    "        instruction = random.choice([\n",
    "            f\"Donne un court descriptif d’un film {genres.lower()} sorti en {year}.\",\n",
    "            f\"Résume brièvement un film {genres.lower()} avec {actors}.\",\n",
    "            f\"Présente en quelques phrases un film {genres.lower()} marquant des années {year}.\",\n",
    "        ])\n",
    "        output = (\n",
    "            f\"{title} est un film {genres.lower()} sorti en {year} avec {actors}. \"\n",
    "            f\"Il raconte une histoire typique de ce genre et est {appreciation}.\"\n",
    "        )\n",
    "\n",
    "    elif itype == \"actors\":\n",
    "        instruction = random.choice([\n",
    "            f\"Quels sont les acteurs principaux du film {title} ?\",\n",
    "            f\"Qui joue dans le film {title} ({year}) ?\",\n",
    "            f\"Donne-moi les acteurs principaux de {title}.\",\n",
    "        ])\n",
    "        output = f\"Les principaux acteurs de {title} ({year}) sont {actors}.\"\n",
    "\n",
    "    elif itype == \"popularity\":\n",
    "        instruction = random.choice([\n",
    "            f\"Explique pourquoi un film comme {title} est connu du grand public.\",\n",
    "            f\"Pourquoi {title} est-il autant cité parmi les films {genres.lower()} ?\",\n",
    "            f\"Qu’est-ce qui peut expliquer le succès de {title} ({year}) ?\",\n",
    "        ])\n",
    "        output = (\n",
    "            f\"{title} ({year}) est un film {genres.lower()} avec {actors}. \"\n",
    "            f\"Il est {appreciation}, ce qui explique qu’il soit souvent recommandé.\"\n",
    "        )\n",
    "\n",
    "    else:  # vibe\n",
    "        instruction = random.choice([\n",
    "            f\"Décris l’ambiance générale d’un film {genres.lower()} comme {title}.\",\n",
    "            f\"Quel type d’ambiance peut-on attendre d’un film {genres.lower()} tel que {title} ?\",\n",
    "            f\"Parle-moi de l’atmosphère d’un film {genres.lower()} sorti en {year}.\",\n",
    "        ])\n",
    "        output = (\n",
    "            f\"{title} est un film {genres.lower()} sorti en {year} avec {actors}. \"\n",
    "            f\"L’ambiance correspond bien à ce qu’on attend d’un film de ce genre.\"\n",
    "        )\n",
    "\n",
    "\n",
    "    instructions.append(\n",
    "        {\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": \"\",\n",
    "            \"output\": output,\n",
    "        }\n",
    "    )\n",
    "\n",
    "with open(\"imdb_instructions.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in instructions:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Dataset d’instructions créé: {len(instructions)} exemples\")\n",
    "\n",
    "# ---------\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"imdb_instructions.jsonl\")[\"train\"]\n",
    "\n",
    "def format_example(example):\n",
    "    return (\n",
    "        f\"Instruction: {example['instruction']}\\n\"\n",
    "        f\"Réponse: {example['output']}\\n\\n\"\n",
    "    )\n",
    "\n",
    "formatted_texts = [format_example(ex) for ex in dataset]\n",
    "\n",
    "from datasets import Dataset\n",
    "hf_dataset = Dataset.from_dict({\"text\": formatted_texts})\n",
    "hf_dataset.save_to_disk(\"imdb_instructions_dataset\")\n",
    "print(hf_dataset[0][\"text\"])\n",
    "\n",
    "# Go to Step 6 to fine-tune the model with this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenisation: 100%|██████████| 5000/5000 [00:00<00:00, 11166.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 5000 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3375/3375 1:06:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.530300</td>\n",
       "      <td>1.490783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.327200</td>\n",
       "      <td>1.451694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.337700</td>\n",
       "      <td>1.444844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "c:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4448442459106445, 'eval_runtime': 38.5274, 'eval_samples_per_second': 12.978, 'eval_steps_per_second': 3.244, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "### IGNORE THIS LAZY COPY PAST FROM 6-11\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "dataset = load_from_disk('imdb_instructions_dataset')\n",
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "block_size = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=block_size,\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenisation\"\n",
    ")\n",
    "\n",
    "print(f\"Tokenized {len(tokenized_dataset)} items\")\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "\n",
    "output_dir = \"./distilgpt2-imdb-instructions-finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faefab",
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: './distilgpt2-imdb-instructions-finetune     d'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The name cannot start or end with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and the maximum length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: './distilgpt2-imdb-instructions-finetune     d'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./distilgpt2-imdb-instructions-finetune     d\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_response\u001b[39m(prompt, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, num_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\pipelines\\__init__.py:883\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    879\u001b[0m     pretrained_model_name_or_path \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig) \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 883\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    884\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    885\u001b[0m         CONFIG_NAME,\n\u001b[0;32m    886\u001b[0m         _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    887\u001b[0m         _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m         _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    889\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mmodel_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    890\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    892\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\hub.py:322\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    265\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    266\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\hub.py:531\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    532\u001b[0m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[0;32m    534\u001b[0m ]\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\hub.py:532\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[0;32m    531\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 532\u001b[0m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[0;32m    534\u001b[0m ]\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\transformers\\utils\\hub.py:143\u001b[0m, in \u001b[0;36m_get_cache_file_to_return\u001b[1;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_cache_file_to_return\u001b[39m(\n\u001b[0;32m    136\u001b[0m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    137\u001b[0m     full_filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m ):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file \u001b[38;5;241m!=\u001b[39m _CACHED_NO_EXIST:\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[0;32m    104\u001b[0m ):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frédéric\\Developer\\4iabd_t1_llm_project\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The name cannot start or end with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and the maximum length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have -- or .. in repo_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars, '-', '_' or '.'. The name cannot start or end with '-' or '.' and the maximum length is 96: './distilgpt2-imdb-instructions-finetune     d'."
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"./distilgpt2-imdb-instructions-finetuned\"\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0 if torch.cuda.is_available() else -1  \n",
    ")\n",
    "\n",
    "def generate_response(prompt, max_length=150, num_sequences=3):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_sequences,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    for i, out in enumerate(outputs, 1):\n",
    "        generated_text = out[\"generated_text\"][len(prompt):].strip()\n",
    "        print(f\"\\n--- Génération {i} ---\")\n",
    "        print(generated_text)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "generate_response(\n",
    "    \"Propose-moi un film d'action récent avec de bons effets spéciaux.\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Je veux un film avec Tom Cruise. Que me conseilles-tu ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Donne-moi un court synopsis d'un film de science-fiction sorti dans les années 2000.\",\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Quelle est la note du film Inception et pourquoi est-il si populaire ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"J'ai envie d'un film drôle et intelligent. Une idée ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Liste les acteurs principaux du film Titanic.\",\n",
    "    max_length=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c53984",
   "metadata": {},
   "source": [
    "### 12.2 LoRA (PEFT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "dataset = load_from_disk(\"imdb_instructions_dataset\")\n",
    "\n",
    "model_name = \"gpt2-medium\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"], \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  \n",
    "\n",
    "block_size = 256\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=block_size,\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized = tokenized.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = tokenized[\"train\"]\n",
    "eval_dataset = tokenized[\"test\"]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-imdb-lora\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./gpt2-imdb-lora\")\n",
    "tokenizer.save_pretrained(\"./gpt2-imdb-lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"./gpt2-imdb-lora\"\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0 if torch.cuda.is_available() else -1  \n",
    ")\n",
    "\n",
    "def generate_response(prompt, max_length=150, num_sequences=3):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_sequences,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    for i, out in enumerate(outputs, 1):\n",
    "        generated_text = out[\"generated_text\"][len(prompt):].strip()\n",
    "        print(f\"\\n--- Génération {i} ---\")\n",
    "        print(generated_text)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "generate_response(\n",
    "    \"Propose-moi un film d'action récent avec de bons effets spéciaux.\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Je veux un film avec Tom Cruise. Que me conseilles-tu ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Donne-moi un court synopsis d'un film de science-fiction sorti dans les années 2000.\",\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Quelle est la note du film Inception et pourquoi est-il si populaire ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"J'ai envie d'un film drôle et intelligent. Une idée ?\",\n",
    "    max_length=150\n",
    ")\n",
    "\n",
    "generate_response(\n",
    "    \"Liste les acteurs principaux du film Titanic.\",\n",
    "    max_length=150\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
